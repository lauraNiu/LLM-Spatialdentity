{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "import os \n",
    "import re \n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from zhipuai import ZhipuAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 微博：香港prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_weibo=pd.read_csv('data_space_score_last_weibo_post.csv')\n",
    "# 1. 微博：香港ip——sample：1k\n",
    "data_weibo_hk=data_weibo[data_weibo['IP地址']=='香港']\n",
    "print(len(data_weibo_hk))\n",
    "# 2. 微博：非香港ip——sample：1k\n",
    "data_weibo_gd=data_weibo[data_weibo['IP地址']!='香港']\n",
    "print(len(data_weibo_gd))\n",
    "sampled_hkip = data_weibo_hk.sample(n=1000)\n",
    "sampled_gdip = data_weibo_gd.sample(n=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ZhipuAI(api_key=\"535af024d07df4663facbf5af957b179.aAxEiUuegF8HcETN\")\n",
    "\n",
    "prompt_learning=\"\"\"\n",
    "香港人和广东人、其他大陆人的语言风格、词汇使用、语法结构、话题内容、地理标记不同，请仔细区分。处理香港人文本时，注重港式粤语词汇、特殊用语及英文混杂的特点。处理广东人文本时，注意广州粤语与香港粤语的区别。请分别输出帖子中香港人、广东人概率，输出概率值（0-100）。\n",
    "例如：\n",
    "帖子：“請問北上大陆的深圳買计数器和生果，可以過到關回香港嗎，唔該，thanks”。 \n",
    "分析： “過到關”粤语词汇， “北上”“大陆”“计数器”“生果”港人常用词汇，涉及香港的情况，粤语夹杂了英语；所以香港人概率90%\n",
    "返回格式：“香港：90%；广东10%；”\n",
    "\"\"\"\n",
    "# 异步运行同步函数的辅助函数\n",
    "async def run_in_executor(executor, func, *args):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return await loop.run_in_executor(executor, func, *args)\n",
    "\n",
    "# 进行API调用的同步函数\n",
    "def call_api_sync(client, post_prompt, post_id):\n",
    "    try:\n",
    "        glm_completion = client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": post_prompt}],\n",
    "            temperature=0.5\n",
    "        )\n",
    "        response = glm_completion.choices[0].message.content if glm_completion.choices else \"No response\"\n",
    "        return (post_id, post_prompt, response)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for post {post_id}: {e}\")\n",
    "        return (post_id, post_prompt, \"Error\")\n",
    "\n",
    "# 主异步函数，处理所有博文\n",
    "async def process_posts(sample):\n",
    "    results_df = pd.DataFrame(columns=[\"博文\", \"判别结果\", \"id\"])\n",
    "    na_df = []\n",
    "    ad_df = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=39) as executor:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        tasks = []\n",
    "        for index, post in sample.iterrows():\n",
    "            post_id = post['id']  \n",
    "            # post_text=post['博文内容']\n",
    "            post_prompt = f\"{prompt_learning}请根据以上标准，对以下博文进行香港、广东人的判别：\\n{post['博文内容']}\\n请您分析,不需要给出如‘好的，我会按照您的要求输出’和‘请注意’等类似的额外说明，仅输出“香港：概率值；广东：概率值”即可\"\n",
    "            task = loop.create_task(run_in_executor(executor, call_api_sync, client, post_prompt, post_id))\n",
    "            tasks.append(task)\n",
    "        \n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        for post_id, post_prompt, response in responses:\n",
    "            if response not in [\"No response\", \"Error\"]:\n",
    "                results_df = pd.concat([results_df, pd.DataFrame({'博文': [post_prompt], '判别结果': [response], 'id': [post_id]})], ignore_index=True)\n",
    "                if response == \"1\":\n",
    "                    ad_df.append(post_id)\n",
    "            else:\n",
    "                na_df.append(post_id)\n",
    "\n",
    "    results_df.to_csv('glm-3_gd_diagnosis_temperature0.5.csv')\n",
    "    print(results_df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sampled_gdip.iloc[150:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "if not loop.is_running():\n",
    "    loop.run_until_complete(process_posts(sample))\n",
    "else:\n",
    "    task = loop.create_task(process_posts(sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 处理数据\n",
    "sampled_gdip_100=pd.read_csv('glm-3_hk_diagnosis_gdip.csv')\n",
    "sampled_hkip_100=pd.read_csv('glm-3_hk_diagnosis_hkip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_prompt_after_score(df):\n",
    "    pattern = re.compile(r\"\\n香港人和广东人、其他大陆人的语言风格、词汇使用、语法结构、话题内容、地理标记不同，请仔细区分。处理香港人文本时，注重港式粤语词汇、特殊用语及英文混杂的特点。处理广东人文本时，注意广州粤语与香港粤语的区别。请分别输出帖子中香港人、广东人概率，输出概率值（0-100）。例如：帖子：“請問北上大陆的深圳買计数器和生果，可以過到關回香港嗎，唔該，thanks”。 分析： “過到關”粤语词汇， “北上”“大陆”“计数器”“生果”港人常用词汇，涉及香港的情况，粤语夹杂了英语；所以香港人概率90%返回格式：“香港：90%；广东10%；\", re.MULTILINE)\n",
    "    df['博文'] = df['博文'].apply(lambda x: re.sub(pattern, \"\", x))\n",
    "\n",
    "    escaped_text = re.escape(prompt_learning)\n",
    "    text_to_delete_1=\"请根据以上标准，对以下博文进行香港、广东人的判别：\"\n",
    "    text_to_delete_2=\"请您分析,不需要给出如‘好的，我会按照您的要求输出’和‘请注意’等类似的额外说明，仅输出“香港：概率值；广东：概率值”即可\"\n",
    "    escaped_text_1=re.escape(text_to_delete_1)\n",
    "    escaped_text_2=re.escape(text_to_delete_2)\n",
    "    df['博文']=df['博文'].str.replace(escaped_text,\"\",regex=True)\n",
    "    df['博文']=df['博文'].str.replace(escaped_text_1,\"\",regex=True)\n",
    "    df['博文']=df['博文'].str.replace(escaped_text_2,\"\",regex=True)\n",
    "    df['博文']=df['博文'].str.replace(\"\\n\",\"\",regex=False)\n",
    "    df['博文']=df['博文'].str.replace(\"?\",\"\",regex=False)\n",
    "    df=df\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_100_clean=del_prompt_after_score(sampled_gdip_100)\n",
    "print(gd_100_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdip_result = pd.merge(data_weibo_gd,gd_100_clean, on='id',how='inner')\n",
    "hk_100_clean=del_prompt_after_score(sampled_hkip_100)\n",
    "hkip_result = pd.merge(data_weibo_hk,hk_100_clean, on='id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "hkip_result.to_csv('hkip_result.csv')\n",
    "gdip_result.to_csv('gdip_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hkip_result=hkip_result[hkip_result['判别结果'].str.contains('香港|广东')]\n",
    "print(len(hkip_result))\n",
    "split_hkip_result=hkip_result['判别结果'].str.split('；|;',expand=True)\n",
    "print(split_hkip_result)\n",
    "hkip_result['香港概率'],hkip_result['广东概率']=split_hkip_result[0],split_hkip_result[1]\n",
    "print(hkip_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hkip_result.loc[98,'香港概率']='30%'\n",
    "hkip_result.loc[98,'广东概率']='70%'\n",
    "hkip_result['香港概率'] = hkip_result['香港概率'].str.replace('[^0-9.%]', '', regex=True)\n",
    "hkip_result['广东概率'] = hkip_result['广东概率'].str.replace('[^0-9.%]', '', regex=True)\n",
    "gdip_result=gdip_result[gdip_result['判别结果'].str.contains('香港|广东')]\n",
    "print(len(gdip_result))\n",
    "split_gdip_result=gdip_result['判别结果'].str.split('；|;',expand=True)\n",
    "print(split_gdip_result)\n",
    "gdip_result['香港概率'],gdip_result['广东概率']=split_gdip_result[0],split_gdip_result[1]\n",
    "print(hkip_result.head())\n",
    "gdip_result['广东概率'] = gdip_result['广东概率'].str.replace('[^0-9.%]', '', regex=True)\n",
    "gdip_result['香港概率'] = gdip_result['香港概率'].str.replace('[^0-9.%]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdip_result['香港概率']  = gdip_result['香港概率'] .replace('0', np.nan)\n",
    "gdip_result['广东概率']  = gdip_result['广东概率'] .replace('0', np.nan)\n",
    "# gdip_result['香港概率'] = gdip_result['香港概率'].str.rstrip('%').astype(float)\n",
    "# gdip_result['广东概率'] = gdip_result['广东概率'].str.rstrip('%').astype(float)\n",
    "gdip_result['香港概率'] = pd.to_numeric(gdip_result['香港概率'].str.rstrip('%'), errors='coerce')\n",
    "gdip_result['广东概率'] = pd.to_numeric(gdip_result['广东概率'].str.rstrip('%'), errors='coerce')\n",
    "# 计算平均值\n",
    "average_percentage_hk = gdip_result['香港概率'].mean()\n",
    "average_percentage_gd = gdip_result['广东概率'].mean()\n",
    "# 将平均值转换回百分数格式（如果需要）\n",
    "average_percentage_str_hk = f\"{average_percentage_hk}%\"\n",
    "average_percentage_str_gd = f\"{average_percentage_gd}%\"\n",
    "print(\"广东ip中，香港概率平均为：\",average_percentage_str_hk)\n",
    "print(\"广东ip中，广东概率平均为：\",average_percentage_str_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 三步方法香港人判别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Step1:判断普通话和粤语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo_loc_space_analysis_result=pd.read_csv('weibo_loc_result_未分列.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ZhipuAI(api_key=\"15a309caa3a78adf440c8072280fad02.ng01HdMeHCOodPUj\")\n",
    "prompt_learning=\"\"\"\n",
    "你是语言分析专家，判断并输出撰文者讲的是粤语和普通话的概率分别是多少，并解释分析过程（概率相加为1）。\n",
    "注意：（1）词语方面：粤语较多保留了古汉语的特征，如“翼”。单音节词比普通话多，如“脷”、 复音词的词素次序与普通话有些不同，如“挤拥”、“齐整”。外来词比其他方言多，如“波”（ball）、“恤衫”（shirt）、“士多”（store）；有特有词，如“嘢”、“点解”、“巴闭”“睇”、古壮语“谂”等。（2）语法方面：粤语语法有修饰语后置的现象，如粤语“你行先”；粤语有回复体（叹翻下冷气）、始续体（食开饭就唔好睇报纸啦），比较句“我大过你”，表给予义的双宾 句“畀本书我”。常将形容词放在名词之后作修饰成分的语法结构，如“水大”“人客”“鱼生”等。（3）如果粤语与普通话的表达一样的情况下，默认为普通话。\n",
    "例子：今日「衬」大陆银行开门…瞓醒又单拖出发北上.今日在莲塘口岸过关唔多人. \n",
    "输出格式：粤语：0.20，普通话：0.80，解释过程 \n",
    "例子：按导航走走错出口（地图真的不靠谱）\n",
    "输出格式：粤语：0.20，普通话：0.80，解释过程\n",
    "\"\"\"\n",
    "# 异步运行同步函数的辅助函数\n",
    "async def run_in_executor(executor, func, *args):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return await loop.run_in_executor(executor, func, *args)\n",
    "\n",
    "# 进行API调用的同步函数\n",
    "def call_api_sync(client, post_prompt, post_id):\n",
    "    try:\n",
    "        glm_completion = client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": post_prompt}],\n",
    "            max_tokens=30,\n",
    "        )\n",
    "        response = glm_completion.choices[0].message.content if glm_completion.choices else \"No response\"\n",
    "        return (post_id, post_prompt, response)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for post {post_id}: {e}\")\n",
    "        return (post_id, post_prompt, \"Error\")\n",
    "\n",
    "# 主异步函数，处理所有博文\n",
    "async def process_posts(sample):\n",
    "    results_df = pd.DataFrame(columns=[\"博文\", \"粤语识别结果\", \"id\"])\n",
    "    na_df = []\n",
    "    ad_df = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=40) as executor:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        tasks = []\n",
    "        for index, post in sample.iterrows():\n",
    "            post_id = post['id']  \n",
    "            post_prompt = f\"{prompt_learning}请对以下博文进行粤语和普通话判别：\\n{post['博文']}\\n请您分析,不需要给出如‘好的，我会按照您的要求输出’和‘请注意’等类似的额外说明，仅按照要求输出识别结果即可\"\n",
    "            task = loop.create_task(run_in_executor(executor, call_api_sync, client, post_prompt, post_id))\n",
    "            tasks.append(task)\n",
    "        \n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        for post_id, post_prompt, response in responses:\n",
    "            if response not in [\"No response\", \"Error\"]:\n",
    "                results_df = pd.concat([results_df, pd.DataFrame({'博文': [post_prompt], '粤语识别结果': [response], 'id': [post_id]})], ignore_index=True)\n",
    "                if response == \"1\":\n",
    "                    ad_df.append(post_id)\n",
    "            else:\n",
    "                na_df.append(post_id)\n",
    "\n",
    "    results_df.to_csv('glm-3_weibo_loc_after_analysis_hk_diag_step1_test_4.csv')\n",
    "    print(results_df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weibo_loc_space_analysis_result.columns)\n",
    "sample = weibo_loc_space_analysis_result[(weibo_loc_space_analysis_result['id'] >=5001) & (weibo_loc_space_analysis_result['id'] <= 6000)]\n",
    "print(len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "if not loop.is_running():\n",
    "    loop.run_until_complete(process_posts(sample))\n",
    "else:\n",
    "    task = loop.create_task(process_posts(sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('glm-3_weibo_loc_after_analysis_hk_diag_step1_test_4.csv')\n",
    "prompt_learning=\"\"\"\n",
    "你是语言分析专家，判断并输出撰文者讲的是粤语和普通话的概率分别是多少，并解释分析过程（概率相加为1）。\n",
    "注意：（1）词语方面：粤语较多保留了古汉语的特征，如“翼”。单音节词比普通话多，如“脷”、 复音词的词素次序与普通话有些不同，如“挤拥”、“齐整”。外来词比其他方言多，如“波”（ball）、“恤衫”（shirt）、“士多”（store）；有特有词，如“嘢”、“点解”、“巴闭”“睇”、古壮语“谂”等。（2）语法方面：粤语语法有修饰语后置的现象，如粤语“你行先”；粤语有回复体（叹翻下冷气）、始续体（食开饭就唔好睇报纸啦），比较句“我大过你”，表给予义的双宾 句“畀本书我”。常将形容词放在名词之后作修饰成分的语法结构，如“水大”“人客”“鱼生”等。（3）如果粤语与普通话的表达一样的情况下，默认为普通话。\n",
    "例子：今日「衬」大陆银行开门…瞓醒又单拖出发北上.今日在莲塘口岸过关唔多人. \n",
    "输出格式：粤语：0.20，普通话：0.80，解释过程 \n",
    "例子：按导航走走错出口（地图真的不靠谱）\n",
    "输出格式：粤语：0.20，普通话：0.80，解释过程\n",
    "\"\"\"\n",
    "escaped_text = re.escape(prompt_learning)\n",
    "text_to_delete_1=\"请对以下博文进行粤语和普通话判别：\"\n",
    "text_to_delete_2=\"\\n请您分析,不需要给出如‘好的，我会按照您的要求输出’和‘请注意’等类似的额外说明，仅按照要求输出识别结果即可\"\n",
    "escaped_text_1=re.escape(text_to_delete_1)\n",
    "escaped_text_2=re.escape(text_to_delete_2)\n",
    "\n",
    "df['博文']=df['博文'].str.replace(escaped_text,\"\",regex=True)\n",
    "df['博文']=df['博文'].str.replace(escaped_text_1,\"\",regex=True)\n",
    "df['博文']=df['博文'].str.replace(escaped_text_2,\"\",regex=True)\n",
    "df['博文']=df['博文'].str.replace(\"\\n\",\"\",regex=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['粤语识别结果'].str.contains('粤语|普通话')]\n",
    "print(len(df))\n",
    "split_df=df['粤语识别结果'].str.split('：|；|;|，|、',expand=True)\n",
    "print(split_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['粤语概率'],df['普通话概率']=split_df[1],split_df[3]\n",
    "df.to_csv('glm-3_weibo_loc_after_analysis_hk_diag_step1_497.csv')\n",
    "df['粤语概率']=pd.to_numeric(df['粤语概率'],errors='coerce')\n",
    "weibo_loc_after_step1=df[df['粤语概率']>=0.5]\n",
    "weibo_loc_after_step1_belowhalf=df[df['粤语概率']<0.5]\n",
    "print(len(weibo_loc_after_step1))# 271/\n",
    "weibo_loc_after_step1.to_csv('weibo_loc_after_step1_test.csv')\n",
    "weibo_loc_after_step1_belowhalf.to_csv('weibo_loc_after_step1_belowhalf.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Step2:判断港式粤语和广式粤语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ZhipuAI(api_key=\"15a309caa3a78adf440c8072280fad02.ng01HdMeHCOodPUj\")\n",
    "prompt_learning=\"\"\"\n",
    "香港和广东均使用粤语，但语言风格、词汇使用、语法结构、话题内容、地理标记不同，请仔细区分。处理香港粤语文本时，注重港式粤语词汇、特殊用语及英文混杂的特点。处理广东粤语文本时，注意广式粤语与港式粤语的区别。请判断并输出社交媒体文本所用为港式粤语和广式粤语的概率（概率取值为0～1，不能为0.5，港式粤语和广式粤语概率和为1）\n",
    "例1：“請問北上大陆的深圳買计数器和生果，可以過到關回香港嗎，唔該，thanks”。 \n",
    "分析： “過到關”粤语词汇， “北上”“大陆”“计数器”“生果”港人常用词汇，涉及香港的情况，粤语夹杂了英语\n",
    "输出格式：港式粤语：0.90，广式粤语：0.10\n",
    "\"\"\"\n",
    "# 异步运行同步函数的辅助函数\n",
    "async def run_in_executor(executor, func, *args):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return await loop.run_in_executor(executor, func, *args)\n",
    "\n",
    "# 进行API调用的同步函数\n",
    "def call_api_sync(client, post_prompt, post_id):\n",
    "    try:\n",
    "        glm_completion = client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": post_prompt}],\n",
    "            temperature=0.5\n",
    "        )\n",
    "        response = glm_completion.choices[0].message.content if glm_completion.choices else \"No response\"\n",
    "        return (post_id, post_prompt, response)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for post {post_id}: {e}\")\n",
    "        return (post_id, post_prompt, \"Error\")\n",
    "\n",
    "# 主异步函数，处理所有博文\n",
    "async def process_posts(sample):\n",
    "    results_df = pd.DataFrame(columns=[\"博文\", \"港式广式识别结果\", \"id\"])\n",
    "    na_df = []\n",
    "    ad_df = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=40) as executor:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        tasks = []\n",
    "        for index, post in sample.iterrows():\n",
    "            post_id = post['id']  \n",
    "            post_prompt = f\"{prompt_learning}请根据以上评分标准，对以下博文进行港式粤语和广式粤语判别：\\n{post['博文']}\\n请您分析,不需要给出如‘好的，我会按照您的要求输出’和‘请注意’等类似的额外说明，仅按照要求输出识别结果即可\"\n",
    "            task = loop.create_task(run_in_executor(executor, call_api_sync, client, post_prompt, post_id))\n",
    "            tasks.append(task)\n",
    "        \n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        for post_id, post_prompt, response in responses:\n",
    "            if response not in [\"No response\", \"Error\"]:\n",
    "                results_df = pd.concat([results_df, pd.DataFrame({'博文': [post_prompt], '港式广式识别结果': [response], 'id': [post_id]})], ignore_index=True)\n",
    "                if response == \"1\":\n",
    "                    ad_df.append(post_id)\n",
    "            else:\n",
    "                na_df.append(post_id)\n",
    "\n",
    "    results_df.to_csv('glm-3_weibo_loc_after_analysis_hk_diag_step2.csv')\n",
    "    print(results_df.head()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选文本\n",
    "print(weibo_loc_after_step1.columns)\n",
    "sample = weibo_loc_after_step1.copy()\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "if not loop.is_running():\n",
    "    loop.run_until_complete(process_posts(sample))\n",
    "else:\n",
    "    task = loop.create_task(process_posts(sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('glm-3_weibo_loc_after_analysis_hk_diag_step2.csv')\n",
    "prompt_learning=\"\"\"\n",
    "香港和广东均使用粤语，但语言风格、词汇使用、语法结构、话题内容、地理标记不同，请仔细区分。处理香港粤语文本时，注重港式粤语词汇、特殊用语及英文混杂的特点。处理广东粤语文本时，注意广式粤语与港式粤语的区别。请判断并输出社交媒体文本所用为港式粤语和广式粤语的概率（概率取值为0～1，不能为0.5，港式粤语和广式粤语概率和为1）\n",
    "例1：“請問北上大陆的深圳買计数器和生果，可以過到關回香港嗎，唔該，thanks”。 \n",
    "分析： “過到關”粤语词汇， “北上”“大陆”“计数器”“生果”港人常用词汇，涉及香港的情况，粤语夹杂了英语\n",
    "输出格式：港式粤语：0.90，广式粤语：0.10\n",
    "\"\"\"\n",
    "escaped_text = re.escape(prompt_learning)\n",
    "text_to_delete_1=\"请根据以上评分标准，对以下博文进行港式粤语和广式粤语判别：\\n\"\n",
    "text_to_delete_2=\"\\n请您分析,不需要给出如‘好的，我会按照您的要求输出’和‘请注意’等类似的额外说明，仅按照要求输出识别结果即可\"\n",
    "escaped_text_1=re.escape(text_to_delete_1)\n",
    "escaped_text_2=re.escape(text_to_delete_2)\n",
    "\n",
    "df['博文']=df['博文'].str.replace(escaped_text,\"\",regex=True)\n",
    "df['博文']=df['博文'].str.replace(escaped_text_1,\"\",regex=True)\n",
    "df['博文']=df['博文'].str.replace(escaped_text_2,\"\",regex=True)\n",
    "df['博文']=df['博文'].str.replace(\"\\n\",\"\",regex=True)\n",
    "df=df[df['港式广式识别结果'].str.contains('港式粤语|广式粤语')]\n",
    "print(len(df))\n",
    "split_df=df['港式广式识别结果'].str.split('：|；|;|，',expand=True)\n",
    "print(split_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['港式广式识别结果'])\n",
    "split_df=df['港式广式识别结果'].str.split('：|，',expand=True)\n",
    "print(split_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['港式粤语概率'],df['广式粤语概率']=split_df[1],split_df[3]\n",
    "print(df.head())\n",
    "df['港式粤语概率']=pd.to_numeric(df['港式粤语概率'],errors='coerce')\n",
    "weibo_loc_after_step2=df[df['港式粤语概率']>=0.5]\n",
    "print(len(weibo_loc_after_step2))# 254\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo_loc_after_step1_step2=pd.merge(weibo_loc_after_step1,weibo_loc_after_step2,on='id',how='inner')\n",
    "print(weibo_loc_after_step1_step2.head())\n",
    "weibo_loc_after_step1_step2=weibo_loc_after_step1_step2.drop(['Unnamed: 0_x','Unnamed: 0_y','博文_y'],axis=1)\n",
    "weibo_loc_after_step1_step2.to_csv('weibo_loc_after_step1_step2.csv')\n",
    "weibo_loc_after_step1_2=pd.merge(weibo_loc_after_step1_step2,weibo_loc_space_analysis_result,on='id',how='inner')\n",
    "print(weibo_loc_after_step1_2.head())\n",
    "weibo_loc_after_step1_2=weibo_loc_after_step1_2.drop(['博文','博文内容','Unnamed: 0.1'],axis=1)\n",
    "weibo_loc_after_step1_2.to_csv('weibo_loc_after_step1_2_包含打分.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Step3:粤语概率小于50%，判断地理位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ZhipuAI(api_key=\"15a309caa3a78adf440c8072280fad02.ng01HdMeHCOodPUj\")\n",
    "prompt_learning=\"\"\"\n",
    "判断这段话的语义是否包含立足香港的话题，包含为1，不包含为0。输出0或1。\n",
    "1代表：将出发地或居住地定为香港（北上深圳、住屯门等香港地名），以及将返回地定为香港（返港等）、对比香港和深圳并提出香港问题的句子；\n",
    "0代表：去香港或回深圳等隐含将深圳作为居住地、不包含立足香港的话题\n",
    "注意：不要与深圳人去香港的帖子混淆\n",
    "例子：周末在邊境，下周要不回深圳\n",
    "输出格式：0\n",
    "\"\"\"\n",
    "# 异步运行同步函数的辅助函数\n",
    "async def run_in_executor(executor, func, *args):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return await loop.run_in_executor(executor, func, *args)\n",
    "\n",
    "# 进行API调用的同步函数\n",
    "def call_api_sync(client, post_prompt, post_id):\n",
    "    try:\n",
    "        glm_completion = client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": post_prompt}],\n",
    "            temperature=0.5\n",
    "        )\n",
    "        response = glm_completion.choices[0].message.content if glm_completion.choices else \"No response\"\n",
    "        return (post_id, post_prompt, response)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for post {post_id}: {e}\")\n",
    "        return (post_id, post_prompt, \"Error\")\n",
    "\n",
    "# 主异步函数，处理所有博文\n",
    "async def process_posts(sample):\n",
    "    results_df = pd.DataFrame(columns=[\"博文\", \"立足香港识别结果\", \"id\"])\n",
    "    na_df = []\n",
    "    ad_df = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=40) as executor:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        tasks = []\n",
    "        for index, post in sample.iterrows():\n",
    "            post_id = post['id']  \n",
    "            post_prompt = f\"{prompt_learning}请根据以上评分标准，对以下博文进行用户是否立足香港判别：\\n{post['博文']}\\n请您分析,不需要给出如‘好的，我会按照您的要求输出’和‘请注意’等类似的额外说明，仅按照要求输出识别结果即可\"\n",
    "            task = loop.create_task(run_in_executor(executor, call_api_sync, client, post_prompt, post_id))\n",
    "            tasks.append(task)\n",
    "        \n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        for post_id, post_prompt, response in responses:\n",
    "            if response not in [\"No response\", \"Error\"]:\n",
    "                results_df = pd.concat([results_df, pd.DataFrame({'博文': [post_prompt], '立足香港识别结果': [response], 'id': [post_id]})], ignore_index=True)\n",
    "                if response == \"1\":\n",
    "                    ad_df.append(post_id)\n",
    "            else:\n",
    "                na_df.append(post_id)\n",
    "\n",
    "    results_df.to_csv('glm-3_weibo_loc_after_analysis_hk_diag_step3_2.csv')\n",
    "    print(results_df.head()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选文本\n",
    "print(weibo_loc_after_step1_belowhalf.columns)\n",
    "sample = weibo_loc_after_step1_belowhalf.copy()\n",
    "print(sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "if not loop.is_running():\n",
    "    loop.run_until_complete(process_posts(sample))\n",
    "else:\n",
    "    task = loop.create_task(process_posts(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('glm-3_weibo_loc_after_analysis_hk_diag_step3_2.csv')\n",
    "prompt_learning=\"\"\"\n",
    "判断这段话的语义是否包含立足香港的话题，包含为1，不包含为0。输出0或1。\n",
    "1代表：将出发地或居住地定为香港（北上深圳、住屯门等香港地名），以及将返回地定为香港（返港等）、对比香港和深圳并提出香港问题的句子；\n",
    "0代表：去香港或回深圳等隐含将深圳作为居住地、不包含立足香港的话题\n",
    "注意：不要与深圳人去香港的帖子混淆\n",
    "例子：周末在邊境，下周要不回深圳\n",
    "输出格式：0\n",
    "\"\"\"\n",
    "escaped_text = re.escape(prompt_learning)\n",
    "text_to_delete_1=\"请根据以上评分标准，对以下博文进行用户是否立足香港判别：\\n\"\n",
    "text_to_delete_2=\"\\n请您分析,不需要给出如‘好的，我会按照您的要求输出’和‘请注意’等类似的额外说明，仅按照要求输出识别结果即可\"\n",
    "escaped_text_1=re.escape(text_to_delete_1)\n",
    "escaped_text_2=re.escape(text_to_delete_2)\n",
    "\n",
    "df['博文']=df['博文'].str.replace(escaped_text,\"\",regex=True)\n",
    "df['博文']=df['博文'].str.replace(escaped_text_1,\"\",regex=True)\n",
    "df['博文']=df['博文'].str.replace(escaped_text_2,\"\",regex=True)\n",
    "df['博文']=df['博文'].str.replace(\"\\n\",\"\",regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['立足香港识别结果']=df['立足香港识别结果'].apply(lambda x:str(x))\n",
    "df_hk=df[(df['立足香港识别结果'].str.contains('0').fillna(False))|(df['立足香港识别结果']=='0')]\n",
    "print(df_hk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
